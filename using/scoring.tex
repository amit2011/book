\chapter{A Closer Look at Scoring}
\label{ch:scoring}
% ##################################################################################################################

\hfill \textbf{Authors:} Kai Nagel, Benjamin Kickhöfer, Andreas Horni, David Charypar

\begin{center} \includegraphics[width=0.3\textwidth, angle=0]{using/figures/scoring-example} \end{center}

\editdone{This text has undergone the professional edit. Please no grammatical changes anymore! They are most-probably wrong.}

% ##################################################################################################################

\section{Good Plans and Bad Plans, Score and Utility}
\label{sec:goodbadplans}

%% \kai{im folgenden habe ich noch ein paar Absätze neu geschrieben, muss daher doppelt gründlich durchgeschaut werden}
%% %
%% \kai{Andreas, hast Du das mal durchgelesen?}

%% \ah{Nur grob, hatte noch auf David Charypar gemacht. Mache ich nächstens.}
%% \ah{jetzt erledigt. Man könnte sich überlegen den ersten Teil von Section~\ref{sec:goodbadplans} nach Section~\ref{sec:inbrief} zu verschieben, ist aber Geschmackssache.}

%% \kai{Wenn es Geschmackssache ist, dann würde ich es so lassen, wie es jetzt ist.}

As outlined in Section~\ref{sec:co-ev} and by Figures~\ref{fig:matsimcycle} and~\ref{fig:ea}, \gls{matsim} is based on a co-evolutionary algorithm; each individual agent learns by maintaining multiple plans, which are scored by executing them in the mobsim, selected according to the score and sometimes modified.  In somewhat more detail, the iterative process contains the following elements:
%
\begin{description}\styleDescription
\item[mobsim] The mobility simulation takes one ``selected'' plan per agent and executes it in a synthetic reality.  This may also be called network loading.

\item [scoring] The actual performance of the plan in the synthetic reality is taken to compute each executed plan's score.

\item [replanning] consists of several steps:
  \begin{enumerate}\styleEnumerate

  \item If an agent has more plans than the maximum number of plans (a configuration parameter), then plans are removed according to a (configurable) plan selector (choice set reduction/plans removal).

    \item For some agents, a plan is copied, modified and then selected for the next iteration (choice set extension/innovation).

  \item All other agents choose between their plans (choice).
  \end{enumerate}
\end{description}

An agent's plans in a given iteration may be considered the agent's \imp{choice set} in that iteration.  As a result, steps~1 and~2 of replanning modify the choice set, while step~3 implements the actual \imp{choice} between options.
%
Choice is typically based on the score; higher score plans are more likely to be selected.  
%
This is discussed in more detail in Chapter~\ref{ch:abta} and~\ref{ch:discretechoice}.  For the time being, note that the three steps of replanning must cooperate for the approach to work; the plans removal step should remove ``bad'' plans and the innovation step should generate ``good'' plans; in both cases, ``good'' means ``able to obtain a high score in the mobsim/scoring''.  Fortunately, due to its evolutionary concept, the approach is fairly robust; the innovation step does not always have to generate good solutions; it is sufficient if \emph{some} of the solutions are good and lead to a high score.

However, it is clear that scoring is a central element of \gls{matsim}.  Only solutions obtaining a high score will be selected by the agent and survive the plans removal step.  Thus, the scoring function needs to be ``correct'' for a given scenario, meaning, more or less, that plans ``performing well'' obtain a higher score than plans that do ``not perform well''.  Whether a performance is good or not, is, in the end, decided by travelers living in a region---some may prefer a congested car trip to a destination, others may prefer a crowded, but affordable, trip by public transit, while others may prefer using the bicycle, even in bad weather.

The typical way to bridge this gap is to use econometric \imp{\gls{utility}} functions; for example, from random utility models \citep[e.g.][]{BenAkivaLerman_1985,Train_2003}, for the score.  However, in \gls{ai}, utility may also be used in a more general way: for example, the \gls{score}, that each individual agent (or the system as a whole), wants to, or should, optimize \citep{RusselNorvig2010ArtificialIntelligence}.  For these reasons, the terms ``\gls{score}'' and ``\gls{utility}'' are mostly interchangeable in the \gls{matsim} context.  Since we will need the concept of a marginal utility, this chapter will mostly speak of 'utility', since it is a bit unusual to talk about 'marginal score'.

The user can configure numerous parameters to calibrate the
%choice behavior.
scoring function.
%scoring function und choice behavior sind nicht identisch: zu letzterem gehört auch das Austauschen von ExpSelectBeta gegen SelectBest oder so.
When users are ready to extend \gls{matsim} in the next book part, they will also learn how to plug in their own customized scoring function.

%% \gls{matsim} is based on \gls{utility}-maximization. Thus, estimated discrete choice models can be applied in \gls{matsim}. However, because of \gls{matsim}'s iterative 
%% structure, and
However, because \gls{matsim} it is based on complete day plans, the application of choice models for parts of day plans only (for example, mode choice) is not straightforward, as detailed in Section~\ref{sec:estimation}.
%
% "due to" vs "because of" see http://web.ku.edu/~edit/because.html
%
Because of the absence of complete-day-utility functions in the literature, \gls{matsim} has
%been
started with the so-called Charypar-Nagel scoring or \gls{utility} function (Section~\ref{sec:charyparnagel}). This scoring function was, at times, modified, extended, or replaced for specific investigations (Section~\ref{sec:appsExtensions}). Readily applicable estimates for a full-day utility function are not yet available, as discussed in Section~\ref{sec:estimation}.

% ##################################################################################################################
\section{The Current Charypar-Nagel Utility Function}
\label{sec:charyparnagel}
% ============================================================================================
\subsection{Mathematical Form}
\label{sec:mathematical-form}

The first, and still basic, \gls{matsim} scoring function was formulated by \citet[][]{CharyparNagel2005ga4acts}, loosely based on the \emph{Vickrey} model for road congestion, as described in \citet[][]{Vickrey_TAER_1969} and \citet[][]{ArnottEtAl_TAER_1993}. Originally, this formulation was established for departure time choice. However, all studies performed so far indicate that the \gls{matsim} function is also appropriate for modeling 
%the
further choice dimensions.
%
It is, however, almost certainly not appropriate for activity dropping and activity addition (see Section~\ref{sec:scoring-current}).

%% As in the discrete choice modeling framework (see Chapter~\ref{ch:discretechoice}), the utility $S_{}$ is composed of a deterministic part $V$ and a random error term $\varepsilon$, i.e., $S_{} = V_{} + \varepsilon$. Except for destination choice the error term is not explicitly generated but stems from the random noise produced by the co-evolutionary process.  \kai{(*)}  Randomness is added in various ways in the process, an example is the order in which agents undergo the replanning (e.g., in which iteration choices are modified). \ah{Hier Diskussion Section~\ref{sec:discussion_scoring} noch weiter vertiefen}.

%% \kai{Andreas, die Aussage (*) stimmt so leider nicht.  Zum einen \emph{erzeugt} die Simulation Noise (wie Du schreibst), zum anderen \emph{parametrisiert} das Logit-Modell (wenn eingestellt) weiteren Noise.  Dies vor allem bei VSP; ihr seid ja weitgehend bei SelectBest geblieben, was sich hier als die theoretisch bessere Lösung herausstellt.}

%% \kai{Noch besser wäre es vermutlich, Deinen Ansatz mit den ``frozen epsilons'' breiter anzuwenden.}

% -------------------------------------------------------------------------------------
\paragraph{Basic Function}

For the basic function, utility of a plan $S_{plan}$ is computed as the sum of all activity utilities $S_{act,q}$ plus the sum of all travel (dis)utilities $S_{trav,mode(q)}$:
%
\begin{equation}
\label{eq:matsimUTF}
S_{plan}=\sum^{N-1}_{q=0} S_{act,q} + \sum^{N-1}_{q=0} S_{trav,mode(q)}
\end{equation}
with $N$ as the number of activities. Trip $q$ is the trip that follows activity $q$. For scoring,the last activity is  merged with the first activity to produce an equal number of trips and activities.
%does not have an associated trip, thus the sum goes only up to $N-1$.  
%\kai{Andreas, Macht Ihr das so?  Die Standard-Variante, die auch am VSP verwendet wird, "näht" die erste und die letzte Aktivität zusammen.  Damit haben wir genauso viele Aktivitäten wie Trips.}
%\ah{dann lag ich hier wohl falsch. korrigiert.}

% -------------------------------------------------------------------------------------
\paragraph{Activities}
%\kai{Andreas, there are no separate beta parameters per activity type.  maybe it would make sense to have them in some cases, but this would be a somewhat larger software change since at this point we cannot attach them to the activity types.}
%\ah{thx!}

The utility of an activity $q$ is defined as follows \citep[see also][p.377ff]{CharyparNagel2005ga4acts}:
\begin{equation}
S_{act,q} = S_{dur,q} + S_{wait,q} + S_{late.ar,q} + S_{early.dp,q} + S_{short.dur,q},
\label{eq:matsimUTFact}
\end{equation}
where:
\begin{itemize}\styleItemize
\item $S_{dur,q}= \beta_{dur} \cdot t_{typ,q} \cdot \ln(t_{dur,q}/t_{0,q})$ 
%
is the utility of performing activity $q$, where opening times of activity locations are taken into account. $t_{dur,q}$ is performed activity duration, $\beta_{dur}$ is the marginal utility of activity duration (or marginal utility of time as a resource---the same for all activities; see Section~\ref{sec:opport-cost-of-time}),
% for its typical duration $t_{typ,q}$, 
and $t_{0,q}$ is minimal duration, or in other words, the duration when utility starts to be positive. 
%
%\kai{Andreas, betaPerf gibt es (absichtlich) nur einmal, und nicht pro Aktivitätentyp.  Unterschiedlicher Zeitdruck kann sich immer noch ergeben, weil EQ~(\ref{eq:mUTTSfull}) für Akvitiäten innerhalb eines bestimmten Zeitfensters höher sein kann (weil dann für diese Aktivitäten $t_{dur,q}$, wg.\ Zeitknappheit, relative gesehen kürzer ist).}  
%%
%\ah{got it}

\medskip

\item $ S_{wait,q} = \beta_{wait} \cdot t_{wait,q}$ 
%
  denotes waiting time spent, for example, in front of a still-closed store; $\beta_{wait}$ is the so-called \emph{direct} (see Section~\ref{sec:opport-cost-of-time}) marginal utility of time spent waiting; and $t_{wait,q}$ is the waiting time.  We recommend leaving $\beta_{wait}$ at zero; also see Section~\ref{sec:schedule-delay-costs}.
  %% \kai{Andreas, Benjamin: Habe den Hinweis auf die ``addition mit der marginal utility of time as a resource'' hier wieder rausgestrichen; ich finde, es auf Null zu lassen ist ein ausreichender Hinweis.  Wir können nicht alles auf einmal erklären.}

  %% $\beta_{wait}$  is in addition to the marginal utility of time as a resource $\beta_{dur}$ from above;


\medskip

\item $S_{late.ar,q}= \left\{
  \begin{array}{l l}
    \beta_{late.ar} \cdot (t_{start,q} - t_{latest.ar,q}) & \quad \text{if $t_{start,q} > t_{latest.ar,q}$}\\
    0 & \quad \text{else}
  \end{array} \right.$
%  
  specifies the late arrival penalty, where $t_{start,q}$ is the activity starting time $q$ and $t_{latest.ar}$ is the latest possible activity starting time (for example, opening times).

\medskip

\item $S_{early.dp} = \left\{
  \begin{array}{l l}
    \beta_{early.dp} \cdot (t_{earliest.dp, q} - t_{end,q}) & \quad \text{if $t_{end,q} > t_{earliest.dp,q}$}\\
    0 & \quad \text{else}
  \end{array} \right.$
%
defines the penalty for staying not long enough, where $t_{end,q}$ is the activity ending time and $t_{earliest.dp,q}$ is the earliest possible activity end time $q$.

\medskip

\item $ S_{short.dur, q} = \left\{
  \begin{array}{l l}
    \beta_{short.dur} \cdot (t_{short.dur, q} - t_{dur,q}) & \quad \text{if $t_{dur,q} < t_{short.dur,q}$}\\
    0 & \quad \text{else}
  \end{array} \right.$
%  
  is the penalty for a 'too short' activity, where $t_{short.dur}$ is the shortest possible activity duration.
\end{itemize}

The config syntax (config version v2) approximately is
\begin{xml}
<module name="planCalcScore" >
   <param name="performing" value="6.0" />
   <param name="waiting" value="-0.0" />
   <param name="lateArrival" value="-18.0" />
   <param name="earlyDeparture" value="-0.0" />
   <parameterset type="activityParams" >
   <param name="activityType" value="work" />
   <param name="typicalDuration" value="08:00:00" />

   <param name="openingTime" value="07:00:00" />
   <param name="latestStartTime" value="09:00:00" />
   <param name="closingTime" value="19:00:00" />

   ...   
   </parameterset>
   ...   
</module>
\end{xml}
%% <param name="scoringThisActivityAtAll" value="true" />
%% <param name="priority" value="1.0" />

%% \kai{at least late arrival and early departure might be moved into the activity itself.  Alternatively, one could have an ``offset'' there.}

\paragraph{Travel} 

%\kai{Andreas, the mode-dependent beta can only be specified by mode, but not by the number of the trip or leg, \ie not by q.  I changed all ``q'' to $mode(q)$.}
%\ah{thx!}

Travel disutility for a leg $q$ is given as 
\begin{equation}
\label{eq:tdisutility}
\begin{matrix}
S_{trav, q} & = & C_{mode(q)} + \beta_{trav, mode(q)} \cdot t_{trav, q} + \beta_{m} \cdot \Delta m_q \\
& & + (\beta_{d, mode(q)} + \beta_{m} \cdot \gamma_{d, mode(q)}) \cdot d_{trav,q} 
%
+ \beta_{transfer} \cdot x_{transfer,q} \, \\
\end{matrix}
\end{equation} 
where:
%
\begin{itemize}\styleItemize

\item $C_{mode(q)}$ is a mode-specific constant.

\item $\beta_{trav, mode(q)}$ is the so-called \emph{direct} (see Section~\ref{sec:opport-cost-of-time}) marginal utility of time spent traveling by mode.  Since \gls{matsim} uses and scores 24-hour episodes, this is, in addition to the marginal utility of time, a resource (again, see Section~\ref{sec:opport-cost-of-time}).

  %% (normally negative or zero); it should \emph{not} contain the marginal utility of time as a resource $\beta_{dur}$ from above.

\item $t_{trav, q}$ is the travel time between activity locations $q$ and $q+1$.

\item $\beta_{m}$ is the marginal utility of money (normally positive).

\item $\Delta m_q$ is the change in monetary budget caused by fares, or tolls for the complete leg (normally negative or zero).
\item $\beta_{d, mode(q)}$ is the  marginal utility of distance (normally negative or zero).
\item $\gamma_{d, mode(q)}$ is the mode-specific monetary distance rate (normally negative or zero).
\item $d_{trav, q}$ is the distance traveled between activity locations $q$ and $q+1$.
\item $\beta_{transfer}$ are public transport transfer penalties (normally negative).
%\kai{is this mode-specific?}\kai{no it is not}, 
and
\item $x_{transfer,q}$ is a 0/1 variable signaling whether a transfer occurred between the previous and current leg.
\end{itemize}
%
The config syntax (config version v2) approximately is
\begin{xml}
<module name="planCalcScore" >
   <param name="marginalUtilityOfMoney" value="1.0" />
   <param name="utilityOfLineSwitch" value="-1.0" />
   <parameterset type="modeParams" >
      <param name="mode" value="car" />
      <param name="constant" value="0.0" />
      <param name="marginalUtilityOfDistance_util_m" value="0.0" />
      <param name="marginalUtilityOfTraveling_util_hr" value="-6.0" />
      <param name="monetaryDistanceCostRate" value="-1.0" />
   </parameterset>
   ...    
</module>
\end{xml}
\atend{check possible re-name of monetaryDistanceCostRate}

%% \benjamin{Irgendwo müsste dann definiert werden, was ``direct'' vs ``indirect'' ist; M.E. einfach ``without'' vs ``with'' (time) costraints.}
%% %
%% \kai{Ich habe jetzt mal ``so-called'' sowie weitere Hinweise auf 3.2.4 eingebaut---natürlich müssen wir checken, dass wir es dort dann erklären.}
%
Equation~(\ref{eq:tdisutility}) the direct utility contribution of travel; see Section~\ref{sec:opport-cost-of-time} for the the full indirect utility, as well as the relation to the \gls{vtts} and Section~\ref{ch:economicEval} for a more general discussion.

Note that distance contributes to disutility in two ways. First, it is included in a direct manner via $\beta_{d, mode(q)}$, which is normal for modes involving physical effort, like walking or cycling. Second, distance is also included monetarily via $\beta_m \cdot \gamma_{d, mode(q)}$, which is normal for car or pt mode, where monetary costs increase depending on distance.
%% \benjamin{Maybe add: `The current specification makes it possible to use either of those approaches for each transport mode'}. \kai{Würde ich weglassen.  Man kann es ja auch beides verwenden, dann wird es halt addiert.}

%% \kai{distance both via distance cost rate and via direct marginal utl.  ok with me, BK will (probably) be less happy. If it stays this way, config needs to be made consistent with text above.}

%% \ah{Hatte, glaube ich, aus dem User Guide abgeguckt.}

%Ist jetzt im code nicht mehr deprecated. kai, dec'14

% ------------
\createfigure[!h!]%
{Illustration of the scoring function.}%
{Illustration of the scoring function. TOP: Individual contributions of activities and legs.  BOTTOM: Score accumulation over a day% 
% \ah{act starts negative, thus, acc score should start with a negative offset, right? thx Marcel!}\kai{right. USED to be zero, but I changed that about a year ago (which also means that DC cannot answer this).  I fixed that in the plot (hopefully; please check if you agree).} \ah{thx}
}%
{\label{fig:scoring-function}}%
{\includegraphics[width=0.8\hsize,trim=0 0 0 0,clip]{using/figures/scoring-example}}%
{}
% ------------

% ====================================================================================
\subsection{Illustration}
\label{sec:utl-fct-illustration}
Figure~\ref{fig:scoring-function} illustrates the scoring function.  Time runs from left to right.  The example shows part of an executed schedule, with a home, work, and lunch activity, connected by a car and walk leg.

Activities are scored with concave functions, modeling decreasing returns to spending more time at the same activity.  Travel, in contrast, is modeled with downward sloping straight lines, where the slope may differ for different modes of transport and there may be an initial offset (alternative-specific constant).  Note the delay between arrival at the workplace and workplace opening time, reflected in no score accumulation during that period.  Agents accumulate those scores over a day, reflected in the bottom graph.

When one assumes all other things (particularly travel times) are equal, then agents maximize their score when activity durations are such that all activities have the same slope ($=$ the same marginal utility; red lines).  This follows from basic economic theory (\cf Section~\ref{ch:economicEval:valuingBehavior}), but can also be seen intuitively; if red lines did not all have the same slope, the agent could gain by extending those activities with steeper slope at the expense of others.  Clearly, this holds only when all other things remain constant, particularly travel times.

% ====================================================================================
\subsection{The \enquote{Wrapping Around} of the Utility Function}
\label{sec:wrap-around}
The \gls{matsim} \gls{mobsim} typically starts at midnight and runs until all plans have reached their final activity.  That is, the \gls{mobsim}, by itself, is not limited to a day.  However, as already stated in Section~\ref{sec:mathematical-form}, the standard scoring function assumes that plans ``wrap around'' to 24-hour days.  Thus, the last activity is merged with the first into one activity. For example, if the first activity ends at 7\,am and the last activity starts at 11\,pm, then it is assumed that this is the \emph{same} activity, with a duration of eight\,hours.

Note that scoring the two activities separately would lead to a different result, because of the nonlinear (logarithmic) form of the utility of performing. For example, $\ln(1) + \ln(7) = \ln(7) \ne \ln(1 + 7) = \ln(8)$.

% ====================================================================================
\subsection{MATSim Scoring, Opportunity Cost of Time, and the VTTS}
\label{sec:opport-cost-of-time}
As a result of the wrap-around concept, travel receives, beyond the typically negative direct marginal utility $\beta_{trav, mode}$, an additional implicit penalty from the \textbf{marginal utility of time as a resource}:
%% \benjamin{potentially rephrase: ``marginal utility of time as a resource''? This is more in line with the literature as we know from Section~\ref{ch:economicEval:valuingBehavior}}
If travel time could be reduced by 
$\Delta t_{trav}$, the person would not only gain from avoiding $\beta_{trav} \cdot \Delta t_{trav}$, but also from gaining additional time for activities (effect of the so-called opportunity cost of time). The \textbf{(total) marginal utility of travel time savings} is thus:
%
\[
mUTTS = - \frac{\partial}{\partial t_{trav}} S_{trav} + \frac{\partial}{\partial t_{dur}}S_{dur} \ .
\]
which is
\begin{equation}
mUTTS = - \beta_{trav}
%\frac{\partial}{\partial t_{trav}} S_{trav} 
+  \beta_{dur} \cdot \frac{t_{typ,q}}{t_{dur,q}} 
\label{eq:mUTTSfull}
\end{equation}
and at the typical duration of an activity
\[
mUTTS \Big|_{t_{dur,q} = t_{typ,q}} = - \beta_{trav} + \beta_{dur} \ , 
\]
where it can be imagined $q$ is the activity immediately following the shortened trip (\cf Section~\ref{ch:economicEval:valuingBehavior}).
%
The marginal utility of travel time savings, $mUTTS$, can then be defined as the indirect effect on the overall time budget, corrected by an offset $\beta_{trav}$ that denotes how much better, or worse, it is to spend that time travelling, rather than ``doing nothing''.\footnote{%
  %
  This is an approximate statement; in the full theory, the reference marginal utility is not given by ``doing nothing'', but by a Lagrange multiplier related to the constraint that a day has 24~hours; again, \cf Section~\ref{ch:economicEval:valuingBehavior}.
  %
} To differentiate $\beta_{trav}$ from the indirect effect, it is sometimes called \textbf{direct marginal utility} of time spent traveling.

%% \atend{chk if default betaTrav was changed to zero when going to print (siehe \url{https://matsim.atlassian.net/browse/MATSIM-335}}

The marginal utility of travel time savings
%at the typical duration
can be transformed to the more common \textbf{\acrfull{vtts}} by division with the marginal utility of money, $\beta_{m}$:
\[
VTTS = \frac{mUTTS}{\beta_{m}} = \frac{- \beta_{trav} + \beta_{dur} \cdot \frac{t_{typ,q}}{t_{dur,q}} }{\beta_{m}} \ ,
\]
and at the typical duration of an activity
\[
VTTS \Big|_{t_{dur,q} = t_{typ,q}} = \frac{mUTTS}{\beta_{m}} \Big|_{t_{dur,q} = t_{typ,q}} = \frac{- \beta_{trav} + \beta_{dur}}{\beta_{m}}
\]
This is important for calibration of the utility function.

%The extensions made over time to the original utility function are described in the next section~\ref{sec:appsExtensions}. Clearly, only a few extensions made it into the default current utility function. \kai{I added a section ``Current version ...'' so wie can summarize which of the extensions actually made it into the default.}

% ============================================================================================
\subsection{The Resulting Modeling of Schedule Delay Costs}
\label{sec:schedule-delay-costs}

\paragraph{Arriving Early}

In the same way as the marginal utility of travel time savings is not only given by $- \beta_{trav}$, but instead by $- \beta_{trav} + \beta_{dur} \cdot \frac{t_{typ,q}}{t_{dur,q}}$, the marginal utility of waiting time savings is given by 
$
mUWTS = - \beta_{wait} + \beta_{dur} \cdot \frac{t_{typ,q}}{t_{dur,q}}: 
$
Even when the direct marginal utility of waiting, $\beta_{wait}$, equals zero, then ``doing nothing'' still eats into the overall time budget and thus incurs the same opportunity cost of time as traveling does.
%
Intuitively, one can imagine that one must leave the previous activity earlier to have a longer waiting time, thus reducing the score of the previous activity.

Thus, as long as one cannot estimate $\beta_{wait}$ separately from $\beta_{dur}$, we recommended leaving $\beta_{wait}$ at zero.

\paragraph{Arriving Late}

Arriving late incurs a marginal utility of $\beta_{late}$, typically negative.  Here, no additional opportunity cost of time is involved. Intuitively, arriving later implies having left the previous activity later.  That is: current activity is shortened by the same amount that the previous activity was extended, leaving the overall score unaffected (\cf Section~\ref{ch:economicEval:valuingBehavior}). 

\paragraph{Vickrey Parameters}

As a result, the Vickrey parameters of $\alpha$ (marginal penalty for arriving early), $\beta$ (penalty for traveling) and $\gamma$ (marginal penalty for arriving late) \citep[as defined by][]{ArnottEtcBottleneck-inelastic} are consistent with the following equations:
\begin{equation}
\begin{array}{ccrc}
-\beta_{wait} + \beta_{dur} \cdot \frac{t_{typ,q}}{t_{dur,q}} & = & \alpha & \\
-\beta_{trav} + \beta_{dur} \cdot \frac{t_{typ,q}}{t_{dur,q}} & = & \beta & \\
- \beta_{late} & = & \gamma & . \\
\end{array}
\end{equation}

%% This has one degree of freedom too many to be solved uniquely.  With setting $\beta_{wait} = 0$ as recommended earlier, one obtains
%% \begin{equation}
%%   \begin{array}{lccc}
%%     \beta_{dur} & = & \alpha & \\
%% \beta_{trav} & = & - \alpha - \beta & \\
%% \beta_{late} & = & - \gamma & .\\
%%   \end{array}
%%   \label{eq:derivation-of-scoring-default}
%% \end{equation}
%% These are the \gls{matsim} default settings for these parameters.

% ##################################################################################################################
\section{Implementation Details}
\label{sec:scoring-current}
This section summarizes the current implementation of the default \gls{matsim} scoring function. The section can be skipped if the reader understands that what has been summarized up to this point is not the full story.

%\kai{Habe das jetzt mal geschrieben, damit es vollständig ist.  Natürlich wird es auf diesem Weg immer detaillierter und damit didaktisch immer ungünstiger.  Bessere Alternativen willkommen.}
%
%\ah{Ich würde das lieber ganz hochnehmen, so dass man den current state ganz zu Beginn des Kapitels mitkriegt. Dafür würde ich "Extensions and replacements of the \acrshort{matsim} scoring function" sehr stark abspecken auf ein paar Sätze mit Pointern in die enstprechenden Kapitel e.g., "UTF for Tel-Aviv can be found in Section~\ref{sec:scenario.telaviv} etc.).}

% -------------------------------------------------------------------------------------
\subsection{Zero Utility Duration}
\label{sec:zero-util-durat}

The duration when an activity's utility is exactly zero is computed by the (somewhat cryptic) expression
\begin{equation}
t_{0,q} := t_{typ,q} \cdot \exp\left( - \frac{10}{(t_{typ,q}/1\,h) \cdot prio} \right) \ ,
\label{eq:zero-utility-duration}  
\end{equation}
where $prio$ is a configurable parameter. This was originally designed so that all activities with the same $prio$ obtain, at their typical duration, the same utility value of $10 \cdot \beta_{dur}$, with the idea that this makes them equally likely to be dropped in a time shortage situation \citep{CharyparNagel2005ga4acts}. Clearly, this does not work as intended, since, as a result, activities accumulating this utility value over a short duration win; thus, without additional constraint the ``home'' activity gets dropped first, which is clearly not plausible. See Section~\ref{sec:future-of-scoring-function} for a discussion of alternatives. In the meantime, the recommendations are:
\begin{itemize}\styleItemize
\item Do not set the \lstinline$priority$ value in the config away from its default value.
\item Recognize that the current \gls{matsim} default scoring/utility function is not suitable for activity dropping.
\end{itemize}

% -------------------------------------------------------------------------------------

% ------------
\createfigure[!h!]%
{Illustration of wrap-around scoring}%
{Illustration of wrap-around scoring. TOP: Normal situation. BOTTOM: Situation where final activity starts at a later time of day then when the first activity ended, resulting in negative duration}%
{\label{tab:negative-durations}}%
{\includegraphics[width=0.8\hsize,trim=0 0 0 0,clip]{using/figures/negative-duration}}%
{}
% ------------

% ------------
\createfigure%
{Extending the slope when the utility function crosses the zero line to negative durations}%
{Extending the slope when the utility function crosses the zero line to negative durations}%
{\label{tab:score-extension}}%
{\includegraphics[width=0.4\hsize,trim=0 0 0 0,clip]{using/figures/score-extension}}%
{}
% ------------

\subsection{Negative Durations}
\label{sec:negative-durations}

In \gls{matsim}, somewhat oddly, it is possible to have activities with negative durations. This can happen because of the ``wrap around'' mechanism, where the last activity of a plan is stitched together with the first activity of the plan, and only that merged activity is scored (\cf Section~\ref{sec:wrap-around}). 
%% \kai{Der Ansatz, dass man alle Aktivitäten des selben Typs erst aufsummiert, würde dies hier natürlich auch lösen.}
In this situation,
% \kai{und auch wenn wir es anders machen würden!!}, 
%it can happen that an agent arrives at the last activity of the plan at a later time-of-day than when the first activity ended.
it can happen that an agent arrives at the last activity of the plan at an earlier time-of-day than when the first activity ended.
%\Karen {Help!! I keep reading this last sentence over and over and it makes no sense. Don't you want to say:.. an agent arrives at the last activity of the plan at an earlier time of day then when...? Or am I delirious ?}". 
%\ah{I think, you are right, otherwise it would not be odd.}
Originally, a score of zero was assigned to these negative duration activities. However, the adaptive agents quickly found out that they could use this to their advantage; expanding this negative duration without a penalty would lead to more time elsewhere, that the agent could use to accumulate score. %% This is a bit similar to the question if a search algorithm should allow infeasible solutions during search, and in an adaptive algorithm needs to be penalized high enough so that does not occur.
%
For an adaptive \gls{algorithm}, a penalty like this needs to be defined so that it guides the adaptation back into the feasible region. Obviously, the penalty must increase with increasing negativity of the duration. It also needs to be larger, \ie more strongly negative, than any score value for a positive activity duration.  The latter is, however, impossible to achieve with a logarithmic form, which tends to $-\infty$ as $t_{dur,q}$ approaches zero from above. The current approach is to take the slope of the expression $\beta_{dur} \cdot t_{typ,q} \cdot \ln( t_{dur,q} / t_{0,q} )$ when it crosses zero, and extend this towards minus infinity (Figure~\ref{tab:score-extension}).

\paragraph*{First and Last Activity not the Same}

Clearly, the wrap-around approach fails if the first and last activity are not the same.  The present code does not look at locations, but gives a warning and problematic results if they are different types.

\subsection{Score Averaging}
\label{sec:score-averaging}

The score $S$ that is computed according to the rules given in this chapter is not assigned directly to the plan, rather, it is exponentially smoothed according to
\begin{equation}
S^k = \alpha \, S + (1-\alpha) \, S^{k-1} \ ,  
\label{eq:score-averaging}
\end{equation}
where $S^k$ is the new memorized score, $S^{k-1}$ is the previously memorized score, $S$ is the score obtained from the plan's execution in the \gls{mobsim}, and $\alpha$ is a ``learning'' or ``blending'' parameter.  The default value of $\alpha$ is one; it can be configured by the line
\begin{xml}
<param name="learningRate" value="..." />
\end{xml}
in the config file.

Non-executed plans just keep their score.

\subsection{Forcing Scores to Convergence}
\label{sec:score-msa}

For many situations, both practical and theoretical (see Section~\ref{sec:score-convergence}), it is desirable that each plan's score converges to its expectation value.  Equation (\ref{eq:score-averaging}) will not achieve that; it just dampens the fluctuations.  A well known approach to force convergence to the expectation value is the \gls{msa}: 
\begin{equation}
S^m = \frac{1}{m} \, S + \frac{m-1}{m} \, S^{m-1} \ .
\label{eq:score-msa}
\end{equation}
This resembles Equation~(\ref{eq:score-averaging}), with two important differences: (1) The fixed blending parameter $\alpha$ is now replaced by a variable $1/m$, and (2) $m$ is not the iteration number but counts how often a plan was executed and thus scored.  This is necessary in \gls{matsim} since a plan is not executed and scored in every iteration.

This behavior can be switched on by the config option
\begin{xml}
<param name="fractionOfIterationsToStartScoreMSA" value="..." />
\end{xml}
The default value is 0.8, meaning that \gls{msa} score averaging starts after 80\% of the iterations.  This is plausibly used together with innovation switch off (Section~\ref{sec:innovation-switchoff}), meaning that \gls{msa} operates on a fixed set of plans.



% ##################################################################################################################
\section{Typical Scoring Function Parameters and Their Calibration}
\label{sec:typicalParams}

%% \kai{Wenn wir das ohnehin nicht genau wissen, dann frage ich mich, ob wir nicht lieber auf $\beta_{trav}=0$ wechseln sollten?} 
%% %
%% \kai{ Siehe \url{https://matsim.atlassian.net/browse/MATSIM-335}}

%% Two frequently applied starting points for utility function calibration are the parameter set proposed by \citet[][]{CharyparNagel2005ga4acts} and the estimates by \citet[][]{Kickhoefer_MastersThesis_2009}.

%% \citet[][p.393]{CharyparNagel2005ga4acts} recommend
The current \gls{matsim} default values are
%for release 7 will be
\begin{equation}
  \begin{array}{lcrl}
\beta_{m} & = & 1\, & utils/monetary unit \\
\beta_{dur} & = & 6\, & utils/h \\
\beta_{trav, mode(q)} & = & -6 & utils/h \\ % \atend{check}, not compiling -> it is mentioned below. \\
\beta_{wait} & = & 0\, & utils/h \\
\beta_{short.dur} & = & 0\, & utils/h \\
\beta_{late.ar} & = & -18\, & utils/h \\
\beta_{early.dp} & = & -18\, & utils/h .\\
  \end{array}
\label{eq:std-params}
\end{equation}
%% \atend{check $\beta_{trav, mode(q)}$}
They are very loosely based on the Vickrey bottleneck model \citep[e.g.][]{ArnottEtcBottleneck-inelastic}; one additional insight: in many of the systems we model, traveling does not seem to be less convenient than ``doing nothing''.  Thus, the \emph{direct} marginal utility of traveling, $\beta_{trav}$, is close to zero and sometimes even positive \citep[see, e.g.,][]{RedmondMokhtarian_Transportation_2001,PawlakEtAl_ICMC_2011} .

%% \kai{there is at least one paper by handy and/or mokhtarian, but i can't find it in the bibtex}.
%% \ah{\citet[][]{, MokhtarianPSalomon_TransResA_2001, }}
%\kai{danke}

\def\betaperf{\beta_{\it perf}}

%% %% (\cf Equation~(\ref{eq:derivation-of-scoring-default})).
%% %% These parameters were derived from \citet[][]{ArnottEtAl_TAER_1993} by also consulting \citet[][]{ChaumetEtAl_2006}. 
%% %% \kai{Andreas, wieso Chaument?} 
%% \ah{So ganz direkt sind ja die Parameter weder von Arnott noch von Vickrey abgeleitet. Chef meinte, dass da nach langen Diskussionen, mit Chaumet (und M. Bernhard, damals am IVT) noch (nach-)kalibriert wurde. Leider lange vor meiner Zeit.

%% \citet[][p.164, p.173]{ArnottEtAl_TAER_1993} defines 
%% $\alpha=5.00\ \$/h$ the shadow cost of travel time,
%% $\beta=3.05\ \$/h$ the unit cost of arriving early at work, and
%% $\gamma=11.88\ \$/h$ the unit cost of arriving late based on the estimations reported by \citet[][Table 2 on p.473]{Small_AER_1982}.
%% Derived from this initial values \citet[][p.382]{CharyparNagel2005ga4acts} define the MATSim utility function as follows [...], where they consider the opportunity costs of $20\ EUR/h$, \ie the costs for doing nothing. 

%% Frage ist hier: wie genau kam man auf die Werte? 

%% In \citet[][p.122]{ArnottEtAl_JUE_1990}, they are defined as $\alpha=6.40\ \$/h$, $\beta=3.90\ \$/h$ and $\gamma=15.21\ \$/h$.

%% %Bernhard and Axhausen: Metaanalysis. Normwerk. Verlässlichkeit ...
%% % Chaumet, R., P. Locher, F. Bruns, D. Imhof, M. Bernard and K.W.\ Axhausen (2007) Verfahren zur Berücksichtigung der Zuverlässigkeit in Evaluationen, final report for VSS 2002/002, Schriftenreihe, 1176, %Bundesamt für Strassen, UVEK, Bern. 
%% }

%% \kai{Arrgghh.  Es ist doch erstaunlich, wie Legenden entstehen können (in dem Fall die Legende, dass 6/12/18 ``the typical Vickrey parameters'' seien); offenbar hat das nie jemand nachgeschaut, inklusive mir selbst.

%%   Vickrey selber hat 0ct/min für trav, 1ct/min für wait, 2ct/min für perf und 4ct/min für late.  Habe das jetzt nicht gelesen, aber auch das scheint die Opportunitätskosten der Zeit somit separat auszuweisen; wenn man das integriert, dann hat man 2ct/min für traf\_eff, 3ct/min für wait\_eff und weiterhin 4ct/min für late.  Hm.

%%   ---

%%   Bei CharyparNagel müsstest Du auch noch in Section 8 reinschauen, da stehen die derzeitigen 6/12/18.

%%   ---

%%   Meine Erinnerung ist wie folgt:

%%   Ich bin mir ziemlich sicher, dass ich die beiden Arnott-et-al papers damals schon kannte (hatte ich in Los Alamos schon gelesen).  Kann aber nicht sagen, ob ich David Charypar die Werte 6/12/18 direkt gegeben habe, oder ob er sie aus dem Paper extrahiert hat.

%%   Benjamin hat das dann mal nachgeschätzt (darauf bezieht sich der Absatz unten; eigentlich müsste es aber m.E.\ Tabelle 5 sein).  Seine Werte (perf/car/wait/late = 2.26/0/0/-11) waren deutlich anders (matsim hat 6/-6/0/-18), aber die verkehrlichen Resultate schienen, soweit wir sehen konnten, nicht anders, insbesondere nicht besser im Vergleich mit Zählungen.

%%   Außerdem hat car=wait=0 zur Folge, dass das Arnott/Vickrey bottleneck model nicht mehr funktioniert, weil im Auto sitzen dann auch nicht mehr schlechter als zu früh kommen ist.  Inhaltlich scheint das (sogar) plausibel, aber vom Gefühl her wird ein solches Modell instabil.

%%   Schlussendlich ist ``wait'' schwierig zu schätzen, weil die meisten Befragungen das nicht sauber abfragen.

%%   Wir hatten dann beschlossen, den matsim-default bei 6/12/18 zu lassen, weil dies zum einen plausible Resultate gibt, und weil die sehr synthetischen Werte deutlich machen, dass man die Werte eigentlich anpassen müsste.

%%   ---

%%   Besonders schlimm finde ich das jetzt nicht.  Wir sollten allerdings das wording vorsichtiger gestalten (``loosely based on Vickrey/Arnott'').  Und aus meiner Sicht hat Chaumet da nichts zu suchen; da müsstet Ihr wissen, welche Rolle er da gespielt hat.

%% }

%% \citet[][]{Kickhoefer_MastersThesis_2009} added monetary variables and income to the \gls{matsim} utility function and performed a mode-specific estimation based on the survey by \citet[][]{VrticEtAl_ResRep_SVI_2007}. The utility function extended by monetary factors was linear, both in the variables and the parameters. Estimated parameters are given in Table 3 of \citet[][]{Kickhoefer_MastersThesis_2009}. The income-dependent utility function was based on \citet[][]{Franklin_PhDThesis_2006}.

%% %% Note, that nowadays the utility function measures in the unit $utils$, where an earlier interpretation was based on monetary terms (e.g., $\EUR$).
%% %
%% %m.E. nicht notwendig.  kai, jan'2015

A possible approach to calibration is as follows:\footnote{%
%
Different groups have different systems; this one is typical for VSP, although it uses ideas from Michael Balmer.
%
}
\begin{enumerate}

%% \item Set $\beta_{scale} \equiv$ \verb$BrainExpBeta$ to $1.0$.  (This is the default.)
%% \kai{Never mentioned so far, I think.  Yet, it is relevant.} 
%% \ah{Section~\ref{sec:selectors}. In the long run, should this not be moved out of scoring to something like ``selectors'' anyway, together with \lstinline$pathSizeLogitBeta$?}\kai{Richtig.  Denke im Moment, dass wir es an dieser Stelle einfach weglassen sollten.  Früher war der default ungünstig, aber das ist ja jetzt besser.}

%% This is normally a positive value.

\item Set $\beta_{m} \equiv$ \verb$marginalUtilityOfMoney$ to whatever is the prefactor of your monetary term in your mode choice logit model.

If you do not have a mode choice logit model, set to $1.0$.  (This is the default.)

This is normally a positive value (since having more money normally increases utility).

\item Set $\betaperf \equiv$ \verb$performing$ to whatever the prefactor of car travel time is in your mode choice mode (probably with a sign change, see below).

If you do not have a mode choice logit model, set to $+6.0$.  (This is the default.)

This is normally a positive value (since performing an activity for more time normally increases utility).

\item Set $\beta_{tt,car} \equiv$ \verb$marginalUtilityOfTraveling...$ to $0.0$. 
%% (For release\,0.7.x, this is the default.) % NOPE
%% \atend{chk if marg utl of trav has been changed to 0})

\emph{It is important to understand this:}  Even if this value is set to zero, traveling by car will be implicitly punished by the so-called opportunity cost of time; if you are traveling by car, you cannot perform an activity; thus, you are (marginally and approximately) losing $\betaperf$.  See Section~\ref{sec:opport-cost-of-time}.

\item Set all other marginal utilities of travel time by mode \emph{relative to the car value}.

E.g.\ if your logit model says something like 
\[
... -6/h \cdot tt_{car} - 7/h \cdot tt_{pt} ... ,
\]
then 
\[
\betaperf = 6 \ , \ \ \beta_{tt,car} = 0 \ , \hbox{ and } \beta_{tt,pt} = -1 \ .
\]

If you do not have a mode choice logit model, set all $\beta_{tt,mode} \equiv$ \verb$travelingXxx$ values to zero (i.e.\ same as car).

\item Set distance cost rates \verb$monetaryDistanceCostRate...$ to plausible values, if you have them.

For the time being, this needs to be negative (not entirely plausible, but it is the way it is).

\item Use the alternative-specific constants $C_{mode} \equiv$ \verb$constant$ to calibrate your modal split.

(This is, however, not completely simple; one must run iterations and look at the result; especially for modes with small shares, one needs to have innovation switched off early enough near the end of the iterations.)

\end{enumerate}

If you end up having your modal split right, but its distance distribution wrong, you probably need to look at different mode speeds.  In our experience, this works better for this than using the $\beta_{tt,mode}$.

Calibrating schedule-based public transport (see Section~\ref{ch:pt}) goes beyond what can be provided here.

% ##################################################################################################################
\section{Applications and Extensions}
\label{sec:appsExtensions}

%% \kai{do we need to mention the change to events-based scoring here?  revise ...}
The default scoring function has been applied and extended for various purposes. 
%% Please be aware, that the \gls{matsim} code base and in particular the scoring functionality has changed a lot in recent years, \eg the scoring is now based on events rather than on plans as it was the case before revision r17026 in October~2011.
%\ah{Btw: when exactly (revision?) did we switch to events-based scoring? Is relevant in other chapters too.}
%\kai{MZ should know this.}
%\thibaut{plan elements from the plans stopped being passed to the scoring function from r17026 on (24 Oct 2011).}
Thus, the historical development is accompanied by various conceptual and technical modifications leading to the current utility function described above. This also means that the reported parameter settings in the literature are an indication, not a direct recommendation.

Important applications for large scenarios are described in Chapter~\ref{ch:scenarios}.

Special utility functions have been developed for car sharing (see Chapter~\ref{ch:carsharing}), social contacts and joint trips (see Chapter~\ref{ch:jointtrips}), parking (see Chapter~\ref{ch:parking}), road pricing (see Chapter~\ref{ch:roadpricing}) and destination innovation (see Chapter~\ref{ch:destinationchoice}), also describing facility loading scoring and inclusion of random error terms. 
 
Future topics, available on an experimental basis, are: a full-blown utility function estimation (Section~\ref{sec:estimation}), inclusion of agent-specific preferences (Section~\ref{sec:agent-specific-prefs}) and application of alternative utility function forms (Section~\ref{sec:future-of-scoring-function}).

% ##################################################################################################################
%\section{Discussion}
%\label{sec:discussion_scoring}
%Will be commented, when chapter is finished. Make final results traceable.
%
%% =====================================================================================
%\subsection{Nutzenfunktion}
%\label{sec:utfd}
%
%
%\benjamin{noch was (relativ wichtiges):
%
%Wir notieren die Nutzenfunktionen in MATSim immer als $V_{i,car} = ...$ etc. Ich würde sehr empfehlen, das im Buch auch so zu machen.
%
%Habe gerade (im noch nicht committeten economic eval Kapitel folgenden Kommentar von mir gesehen, und dachte ich teile das mal:
%
%"I would strongly recommend to use $V_p$ instead of $S_p$ for an agent's plan even though this is not entirely the same as in Discrete Choice Theory, since some of the $\varepsilon$ is already captured by the simulation noise that Gunnar called $\eta$...In consequence, the score is NOT equal to $V_p$. 
%We should explain that in more detail."
%
%Bei deinen frozen epsilon und BestSelect ist $S_{}$ dann zwar wahrscheinlich richtig, aber so wie es jetzt in dem Kapitel über Charypar-Nagel steht ist es m.E. falsch.
%
%Was meinst du/ihr?
%}
%
%\gunnar{ja, zugestimmt. Vielleicht
%
     %\[U = V + eps\]
%
%wie üblich beibehalten und dann
%
     %\[V = \sum_i b_i E\{x_i\}\]
%
%schreiben, wobei $x_i$ weiterhin stochastische Attribute aus der mobsim sein können (und der Erwartungswert-Operator bei deterministischen Attributen ja nicht schadet). Das ist dann vermutlich auch konsistent mit der Weise, auf die die Modelle geschätzt wurden. Das eps würde dann alles mögliche absorbieren können (gumble, frozen, mobsim).
%}
%
%
%\ah{Dinge, welche man m.E. dabei irgenwie noch einbeziehen müsste:
%
%-$\varepsilon$ gibt es explizit momentan nur für Destination Choice (Mail Gunnar).
%
%-ohne $E\{.\}$ ist man mit $S_{}$ wohl mindestens so nahe an der Wahrheit dran wie mit $V$ (wegen $\eta$) (Mail Benjamin).
%
%- Konsistenz: in sehr vielen Publ. kommt seit Jahren $S_{plan}=S_{act}+S_{travel}$ vor. Könnte mir vorstellen, dass gerade neue User verwirrt sind, wenn wir davon abrücken (ohne grosse Not?-> $\eta$!).
%}
%
%\ah{Gunnars Mail doch noch kapiert. So müsste es gehen.}
%
%% =====================================================================================
%\subsection{Score and Its Interpretation}
%\label{sec:scored}
%\kai{
%Die ursprüngliche Aussage war: 
%
%(1) Matsim produziert einen "score", analog einer "fitness" in evolutionary algorithms.  Notiert als "S".
%
%(2) Wie das dann interpretiert wird, ist ein zweiter Schritt. (Z.B. ob als U oder als V.)
%
%
%IVT argumentiert, dass sämtlicher Noise durch die Simulation erzeugt wird, und verwendet "SelectBest" bei choice.  Dann ist U = S.  (Also: Aller Nutzen des Agenten kommt aus dem Score.)
%
%VSP verwendet ein logit model bei choice ... und argumentiert damit letztendlich (aber bisher nicht absichtlich), dass beim choice \textbf{weiterer} (durch den scale parameter parametrisierter) noise hinzugefügt wird.  Dann ist U = S + epsilon .   (Wichtig: Es gibt Nutzen für den Agenten über den Score hinaus.)
%
%
%Für den zweiten Fall gilt Gunnars Theorie von conceptual meeting: "one can only convincingly claim that S = V when S is an expected value".
%
%Ich weiß gar nicht, was für den ersten Fall gilt.
%
%
%Kohärent aufschreiben kann man das m.E. nur, indem man konsistent bei "S" bleibt, und den Schritt der Interpretation separiert von dem, was MATSim tut.
%
%
%Wie jetzt weiter?
%
%
%(a) matsim output konsistent als "S" notieren statt "U" oder "V"?
%
%(Der Latex-Aufwand würde sich m.E. in Grenzen halten; es wäre m.E. die konsistenteste Lösung; fraglicher wäre die Lesbarkeit.)
%
%
%(b) bei "U" bleiben, aber Fußnoten dranmachen im Sinne von "matsim agent-based score is loosely interpreted as agent-based utility; for a discussion and relation to discrete choice see Chap XY and YZ".
%
%
%(c) weitere Vorschläge?
%
%
%Ich bin auf jeden Fall derzeit skeptisch, ob wir wirklich alle U nach V umwandeln sollen, und ich bin auch skeptisch, ob wir bereits im "using" Teil überhaupt von U = V + eps sprechen wollen.
%
%
%Kommentare?  Meinungen?
%
%}
%
%\gunnar{ich möchte meine Antwort hierauf gerne ein paar Stunden, max einen Tag, aufschieben und das "choice models in matsim" Kapitel entsprechend formulieren.}
%
%\ah{Bin nicht sicher, ob das hier am IVT tatsächlich alle machen, oder nur ich, wenn ich das Best-Response-Modul Destination Choice anwerfe. Ich jedenfalls nehme auch Logit, wenn ich keine Destination Choice mache.
%
%Bis zu Gunnars Kapitel bei "S" bleiben und dann erst den Link zu Discrete Choice machen, fände ich eine gute Lösung. Man müsste im Scoring-Kapitel (und Glossar) dann halt kurz erklären warum wir jetzt plötzlich nicht mehr wie alle die Jahre "U", sondern vorerst mal "S" schreiben. U=V+eps ist ja eigentlich in den ersten beiden Teilen nur für Zielwahl wirklich relevant, und das kriege ich dann schon auf Gunnars Kapitel angepasst.
%
%Verständnisfrage: Die Aussage gilt nur für Random-Mutation-Settings, oder? Für Route-Choice, z.B., wird bloss das Konvergenzverhalten beeinflusst, oder? }
%
%\kai{
%Leider keine einfache Sache, siehe auch unsere Kapitel über econ eval. 
%
%(A) Was macht matsim derzeit?
%
%(1) Ein choice model $\exp(V_i) / \sum_j \exp(V_j)$ impliziert einen echten Nutzen von U = V + eps .
%
%(2) Der erwartete (= mittlere) Nutzen ist dann der logsum term:  $E(U) = ln \sum_j \exp(V_j)$
%
%(3) Ordnen wir die Pläne so, dass der Plan mit dem höchsten Nutzen die Nummer 1 ist.  dann
%
%$ln \sum_j \exp(V_j) = ln ( \exp(V_1) * ( 1 + \sum_{j \ge 2} \exp(V_j - V_1) ) = V_1 + ln( 1 + ... )$
%
%Das ist offensichtlich größer als $V_1$; der mittlere Nutzen ist größer als der höchste Score!
%
%So geht das ganz generell: Die Hinzufügung weiterer Pläne, selbst wenn sie schlechter sind als der beste, erzeugen bei diesem Ansatz zusätzlichen mittleren Nutzen.
%
%Das gilt auch dann, wenn sich die zusätzlichen Pläne nur in der Route unterscheiden.
%
%
%(B) Ist das sinnvoll?
%
%Fraglich.  Oft hat matsim am Ende der Iterationen 5 identische Pläne; die erzeugen dann in der Rechnung $ln(5)$ an zusätzlichem Nutzen; das ist aber auch formal nicht richtig, weil vollständig korrelierte Optionen nicht zum Nutzen beitragen dürfen.  Gunnar wird vielleicht einwenden, dass man hier "path size logit" verwenden sollte ... 
%
%... ich selber würde inzwischen sagen, dass ich finde, dass das zu kompliziert wird.  Die Schönheit des agenten-basierten Ansatzes war doch, dass dass man auch ohne solche statistisch komplizierten Argumente auskommt.
%
%
%(C) Was tun?
%
%Mittelfristig ist das eine Forschungsfrage.  Ein erster Ansatz wäre u.E. eine Variante Deiner frozen epsilons auch für andere Situationen.  Jeder neue Plan kommt dann zusammen mit einem neuen frozen epsilon, wobei die Bandbreite sich eigentlich daran orientieren müsste, wie sehr sich dieser Plan von anderen Plänen unterscheidet.  Dann z.B.:
%
%* nur neue Route -- frozen epsilon wird übernommen
%
%* ...
%
%* neue location -- frozen epsilon stammt aus Horni-Ansatz
%
%Damit ist dann klar, dass der Agent einen $score > V_best$ erhalten kann; das geht ja bereits bei Deinem Paper so.  Aber alle epsilons ist dann bereits im "S" drin, und der Score, den matsim ausspuckt, ist dann einfach nur der tatächliche Nutzen, den der Agent erhält.
%
%(Leider weiß ich nicht, was das mit Cadyts macht, aber man könnte behaupten, dass Cadyts halt genau die frozen epsilons kalibriert.)
%
%
%Nun ja.  Wolltest Du es so genau wissen?  :-)
%
%}
%
%\kwaah{
%danke, soweit ich mich erinnere (siehe Ben-Akiva und Lerman) ist der log sum Term der maximale Nutzen ueber alle Alternativen, d.h. solange die Alternativen nicht identisch
%sind, erhoeht eine wahre zusaetzliche Alternative den Nutzen des Satzes der Alternativen. 
%
%Das ist auch das Argument hinter der Nutzung des log sum terms als Wohlfahrtsmass. 
%}
%
%\gunnar{
%Es gilt in beiden Fällen, so war es ja konstruiert. Kombiniere U = S (1. obiger Abschnitt) und S = V (3. Abschnitt); das liefert U = V. Da $V=E\{U\}$ per Definition, gilt das weiterhin nur, wenn U (also S im 1. Abschnitt) ein Erwartungswert ist.
%
%> bereits im "using" Teil überhaupt von U = V + eps sprechen:
%
%Nur S im "using" Teil, mit einem Verweis auf Teil 3.
%}

% ##################################################################################################################
%\section{Extensions}
% ======================================================================================================================
%\paragraph{Project Westumfahrung Zürich:}
%Project Westumfahrung \citep[][]{BalmerEtAl_ResRep_bdktzrh_2009} used the Zürich scenario version 1 \citep[][]{HorniEtAl_TechRep_IVT_2011_a}. Only car traffic was simulated with $\beta_{perf,q}=6.0\ utils/h$ and $\beta_{trav,q}=-6.0\  utils/h$. No further penalties were applied. Typical activity durations were provided with the config with half-hour resolution and empirically derived from the Swiss microcensus.

% ======================================================================================================================
%\paragraph{Project Location-Based Services:}
%\citet[][]{BalmerEtAl_ResRep_datapuls_2010} was simulated on the Swiss scenario version 2 \citep[][]{HorniEtAl_TechRep_IVT_2011_a}. Innovations related to the utility function are agent-specific typical activity durations and facility-specific opening hours. Summation of activity duration for activities of the same duration (denoted as $S_{cum}$) was added by \citet[][p.9 and p.28]{BalmerEtAl_ResRep_datapuls_2010}. Facility-loading penalties were included as detailed below. The parameters \citep[][Table 2 on p.31]{BalmerEtAl_ResRep_datapuls_2010} of the multi-modal utility function including monetary costs was heavily based on the estimates by Kickhöfer \citep[][]{Kickhoefer_MastersThesis_2009}. Egress and access times to and from public transport stops was included, public transport travel times were not simulated but imputed. Due to problems with spreading of many plans into the next day a penalty for too long day plans was added.

% ======================================================================================================================
%\paragraph{Project Herbie Mode Choice:}
%Project Herbie \citep[][]{VitinsEtAl_VW_2012} provided a thorough calibration of the multi-modal Zürich scenario extended by public transport simulation, cross-border and freight traffic, tolling, parking pricing, park \& ride and joint riding. The mode-share calibration targeting on distances and shares was based on the Swiss microcensus \citep[][p.18]{VitinsEtAl_VW_2012}.   

% ======================================================================================================================
%\paragraph{Project Tel-Aviv:}
%\citet[][]{BekhorEtAl_TRB_2011, DoblerEtAl_TechRep_IVT_2014} combine MATSim with the Tel-Aviv activity-based model \citep[][]{CambrigeSystemsInc_ResRep_TelAviv_2008}. Its multi-nomial zone-based utility function is integrated into MATSim by disaggregating the zones into facilities.

% ======================================================================================================================
%\paragraph{Singapore:}
%In the Singapore scenario \citep[][]{ErathEtAl_IATBR_2012} the basic multi-modal Charypar-Nagel utility function is applied. Its parameters derived from the Singapore Land Transport Authority (LTA) model. The utility function is measured in SGD rather than utils.

% ======================================================================================================================
%\paragraph{Car Sharing:}
%\citet[][p.10]{CiariEtAl_TechRep_IVT_2014} used the following car sharing specific utility function terms: access and egress time costs for walking, monetary cost of distance, and rental costs (constant and time-dependent). Simulations were performed for the multi-modal Zürich scenario with the parameter set described in Table 1.
%
% ======================================================================================================================
%\paragraph{Parking:}
%\citet[][]{WaraichAxhausen_TechRep_IVT_2012} extended the utility function by a parking term including walking to and from the parking lot (p.7) and parking costs (p.9). Simulations were run for the Zürich car traffic scenario. \citet{WaraichEtAl_unpub_TRB_2013} implemented a parking location choice model based on parameters estimated by \citet[][]{WeisEtAl_TechRep_TSMS_2013}.
%
% ======================================================================================================================
%\paragraph{Road Pricing:}
%Road pricing is a MATSim extension. It can be added by an event listener to the controler. The utility function then gets money events, converts them, and accumulates them to the rest of the score which is given in utils.
%
% ======================================================================================================================
%\paragraph{Social Contacts and Joint Trips:}
%There are two approaches modeling social contacts in MATSim, \citet[][]{Hackney_PhDThesis_2009} and the work performed by Thibaud Dubernet. Both modify scoring in a similar way; by increasing each individuals score if they coincidently perform an activity of the same type in the same facility. Both restricted the type to leisure to begin with. Dubernet also includes joint car rides in that calculation; but sometimes instead the marginal utility of travel is modified (Thibaud Dubernet, personal communication, March 2014). Linear and logarithmic functions have been tried by Dubernet, where recent experiments showed that, as expected, a logarithmic function increases the number of friend contacts, giving the microsimulation user another calibration parameter. 
%
% ======================================================================================================================
%\paragraph{Destination Choice:}
%Goal of the estimation described by \citet[][]{Horni_PhDThesis_2013} were first indications about quantitative relation of MATSim time parameters and further choice attributes. Focusing on destination choice, attributes used for estimation were \emph{store size} (in categories), \emph{price level} (in categories) and \emph{additional linear distance} to the store similar to the detour distance defined in \citet[][]{ArentzeTimmermans_TRR_2007}.
%
%Clearly, for direct application in MATSim, travel times rather than distances would have been better, but this information was not available consistently. A minimal set of variables was chosen due to data availability and as the main goal was laying an instructive base for future MATSim utility function estimations and their application in the MATSim Zürich scenario. Alternative-specific constants were not assigned to destinations to prevent over-fitting \citep[][]{BierlaireEtAl_TransScience_1997}.
%
%Although the estimated parameters had to be enlarged to show significant effects, their relation was correct as experiments with this extended and adapted model showed a surprisingly substantial decrease of the relative error in count data.
%
%Non-linear estimated models containing travel time are scarce as travel time is an unreliable information in surveys. A way to approximately applying simple linear distance models to the non-linear time-based MATSim utility function is discussed in Section 5.5.1 of \citet[][]{Horni_PhDThesis_2013}.
%

% ======================================================================================================================
%\paragraph{Agent-Specific Preferences:}
%In project Surprice \citet[][]{HorniEtAl_TechRep_IVT_2012_a, HorniAxhausen_TechRep_IVT_2014}, agent-specific travel preferences and individual income-dependent marginal utilities of money are incorporated. It is simulated with a 1\% multi-modal Zürich scenario, the preference values however, are assigned randomly.

% ##################################################################################################################
\ifthenelse{\boolean{printBibPerChapter}}{\bibpc}{}

% ##################################################################################################################
% Local Variables:
% mode: latex
% mode: reftex
% mode: visual-line
% TeX-master: "../main"
% comment-padding: 1
% fill-column: 9999
% End: 
